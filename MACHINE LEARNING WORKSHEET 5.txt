                                                                                     MACHINE LEARNING
                                                                                       WORKSHEET – 5
                                                                                          ANSWERS



1. (D) None of these

2. (A) max_depth

3. (B) RandomOverSampler
   (C) RandomUnderSampler

4. (B) 1 only

5. (D) 1-3-2

6. (A) Decision Trees

7. (C) CART can only create binary trees (a maximum of two children for a node), and CHAID can create multiway trees (more than two children for a node)

8. (A) Ridge will lead to some of the coefficients to be very close to 0
   (D) Lasso will cause some of the coefficients to become 0

9. (C) Use ridge regularisation
   (D) use Lasso regularisation

10. (A) Overfitting
    (C) Underfitting

11. 

12. In case of data imbalance problem in classification, techniques which can be used to balance the dataset are : -
   
    * Use the right evaluation metrics
    * Resample the training set
    * Use K-fold Cross-Validation in the right way
    * Ensemble different resampled datasets
    * Resample with different ratios
    * Cluster the abundant class
    * Design own models

13. The major difference between SMOTE and ADASYN is the difference in the generation of synthetic sample points for minority data points.

    SMOTE: Synthetic Minority Over sampling Technique (SMOTE) algorithm applies KNN approach where it selects K nearest neighbors, joins them and creates the synthetic samples in the space. 
           The algorithm takes the feature vectors and its nearest neighbors, computes the distance between these vectors. The difference is multiplied by random number between (0, 1) and it 
           is added back to feature. SMOTE algorithm is a pioneer algorithm and many other algorithms are derived from SMOTE.

    ADASYN: ADAptive SYNthetic (ADASYN) is based on the idea of adaptively generating minority data samples according to their distributions using K nearest neighbor. The algorithm adaptively 
            updates the distribution and there are no assumptions made for the underlying distribution of the data.  The algorithm uses Euclidean distance for KNN Algorithm. 
   
   The key difference between ADASYN and SMOTE is that the former uses a density distribution, as a criterion to automatically decide the number of synthetic samples that must be generated for
   each minority sample by adaptively changing the weights of the different minority samples to compensate for the skewed distributions. The latter generates the same number of synthetic samples
   for each original minority sample.

14. GridSearchCV - GridSearchCV is used to tune the hyper parameters that on which the particular hyper parameter one can get the good result. The GridSearchCV will allow us to find out the best
                   hyper vparameter and the selected hyper parameter the best hyper parameter will be given into the model to be further trained.

                   Suppose Decesion Tree Classifier is there : - 
        
                   dtc = DecisionTreeClassifier(Criterion='gini', 'criterion')

                   In each of the algorithm, there are certain hyper parameters and if we tune those hyper parameters, the results are more good.

     GridSearchCV : -

     param_grid = {'Criterion' : ['gini','entropy']}

     gd = GridSearchCV(estimator, param_grid, CV=5)

     gd.fit(x,y)  - This gridSearchCV will give us the best parameter, the best score also.

     And the best value which is GridSearchCV is giving to us then we can use that particular hyper parameter into the model.

15. The evaluation metric used to evaluate a regression model are : -

    (1) Mean Squared Error(MSE):  MSE or Mean Squared Error is one of the most preferred metrics for regression tasks. It is simply the average of the squared difference between the target value and the
                                  value predicted by the regression model. As it squares the differences, it penalizes even a small error which leads to over-estimation of how bad the model is. It is preferred 
                                  more than other metrics because it is differentiable and hence can be optimized better.

    (2) Root Mean Squared Error:  RMSE is the most widely used metric for regression tasks and is the square root of the averaged squared difference between the target value and the value predicted by the model. 
                                  It is preferred more in some cases because the errors are first squared before averaging which poses a high penalty on large errors. This implies that RMSE is useful when large 
                                  errors are undesired.

    (3) Mean Absolute Error:      MAE is the absolute difference between the target value and the value predicted by the model. The MAE is more robust to outliers and does not penalize the errors as extremely as MSE.
                                  MAE is a linear score which means all the individual differences are weighted equally. It is not suitable for applications where you want to pay more attention to the outliers.

    (4) R² Error:                 Coefficient of Determination or R² is another metric used for evaluating the performance of a regression model. The metric helps us to compare our current model with a constant baseline
                                  and tells us how much our model is better. The constant baseline is chosen by taking the mean of the data and drawing a line at the mean. R² is a scale-free score that implies it doesn't 
                                  matter whether the values are too large or too small, the R² will always be less than or equal to 1.

    (5) Adjusted R²:              Adjusted R² depicts the same meaning as R² but is an improvement of it. R² suffers from the problem that the scores improve on increasing terms even though the model is not improving which
                                  may misguide the researcher. Adjusted R² is always lower than R² as it adjusts for the increasing predictors and only shows improvement if there is a real improvement.

    
 